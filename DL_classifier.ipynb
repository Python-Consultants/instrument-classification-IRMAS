{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_all = pd.read_csv('traindata_raw.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-91.963967</td>\n",
       "      <td>105.096580</td>\n",
       "      <td>-30.380742</td>\n",
       "      <td>19.623144</td>\n",
       "      <td>7.864010</td>\n",
       "      <td>28.667215</td>\n",
       "      <td>9.144874</td>\n",
       "      <td>8.710527</td>\n",
       "      <td>7.943736</td>\n",
       "      <td>3.226403</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.736931</td>\n",
       "      <td>0.362849</td>\n",
       "      <td>6.496445</td>\n",
       "      <td>-2.391663</td>\n",
       "      <td>-11.616247</td>\n",
       "      <td>-9.043096</td>\n",
       "      <td>-7.675692</td>\n",
       "      <td>-5.406505</td>\n",
       "      <td>9.618369</td>\n",
       "      <td>voi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85.366237</td>\n",
       "      <td>101.649270</td>\n",
       "      <td>-33.703561</td>\n",
       "      <td>23.957620</td>\n",
       "      <td>-0.626421</td>\n",
       "      <td>25.965370</td>\n",
       "      <td>3.521350</td>\n",
       "      <td>8.057379</td>\n",
       "      <td>12.864924</td>\n",
       "      <td>2.670274</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.326123</td>\n",
       "      <td>-4.981471</td>\n",
       "      <td>2.376308</td>\n",
       "      <td>-3.255108</td>\n",
       "      <td>-5.930639</td>\n",
       "      <td>-9.866653</td>\n",
       "      <td>-7.677595</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>10.225007</td>\n",
       "      <td>voi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-70.602010</td>\n",
       "      <td>96.136897</td>\n",
       "      <td>-44.954211</td>\n",
       "      <td>22.478617</td>\n",
       "      <td>-5.727435</td>\n",
       "      <td>27.195755</td>\n",
       "      <td>4.279557</td>\n",
       "      <td>9.121658</td>\n",
       "      <td>15.989916</td>\n",
       "      <td>4.912378</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.221855</td>\n",
       "      <td>-5.024254</td>\n",
       "      <td>0.142265</td>\n",
       "      <td>-6.889198</td>\n",
       "      <td>-2.167274</td>\n",
       "      <td>-6.240126</td>\n",
       "      <td>-8.406016</td>\n",
       "      <td>1.081667</td>\n",
       "      <td>8.671729</td>\n",
       "      <td>voi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-70.923855</td>\n",
       "      <td>100.204938</td>\n",
       "      <td>-48.644282</td>\n",
       "      <td>19.635599</td>\n",
       "      <td>-3.416086</td>\n",
       "      <td>28.776793</td>\n",
       "      <td>8.279170</td>\n",
       "      <td>6.841322</td>\n",
       "      <td>16.674616</td>\n",
       "      <td>4.500598</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.981285</td>\n",
       "      <td>-4.582226</td>\n",
       "      <td>4.517435</td>\n",
       "      <td>-5.094420</td>\n",
       "      <td>-0.759547</td>\n",
       "      <td>-3.510984</td>\n",
       "      <td>-9.008126</td>\n",
       "      <td>-4.384427</td>\n",
       "      <td>5.054848</td>\n",
       "      <td>voi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-72.968648</td>\n",
       "      <td>101.455395</td>\n",
       "      <td>-47.118626</td>\n",
       "      <td>16.485796</td>\n",
       "      <td>-4.556425</td>\n",
       "      <td>34.225432</td>\n",
       "      <td>9.645169</td>\n",
       "      <td>2.621069</td>\n",
       "      <td>14.869865</td>\n",
       "      <td>4.898435</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.666123</td>\n",
       "      <td>-7.110345</td>\n",
       "      <td>4.923937</td>\n",
       "      <td>-2.876247</td>\n",
       "      <td>-4.629001</td>\n",
       "      <td>-7.439723</td>\n",
       "      <td>-9.067987</td>\n",
       "      <td>-6.983652</td>\n",
       "      <td>1.462925</td>\n",
       "      <td>voi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3         4          5         6  \\\n",
       "0 -91.963967  105.096580 -30.380742  19.623144  7.864010  28.667215  9.144874   \n",
       "1 -85.366237  101.649270 -33.703561  23.957620 -0.626421  25.965370  3.521350   \n",
       "2 -70.602010   96.136897 -44.954211  22.478617 -5.727435  27.195755  4.279557   \n",
       "3 -70.923855  100.204938 -48.644282  19.635599 -3.416086  28.776793  8.279170   \n",
       "4 -72.968648  101.455395 -47.118626  16.485796 -4.556425  34.225432  9.645169   \n",
       "\n",
       "          7          8         9  ...          31        32        33  \\\n",
       "0  8.710527   7.943736  3.226403  ...   -1.736931  0.362849  6.496445   \n",
       "1  8.057379  12.864924  2.670274  ...   -5.326123 -4.981471  2.376308   \n",
       "2  9.121658  15.989916  4.912378  ...   -5.221855 -5.024254  0.142265   \n",
       "3  6.841322  16.674616  4.500598  ...   -5.981285 -4.582226  4.517435   \n",
       "4  2.621069  14.869865  4.898435  ...   -7.666123 -7.110345  4.923937   \n",
       "\n",
       "         34         35        36        37        38         39  label  \n",
       "0 -2.391663 -11.616247 -9.043096 -7.675692 -5.406505   9.618369    voi  \n",
       "1 -3.255108  -5.930639 -9.866653 -7.677595  0.697900  10.225007    voi  \n",
       "2 -6.889198  -2.167274 -6.240126 -8.406016  1.081667   8.671729    voi  \n",
       "3 -5.094420  -0.759547 -3.510984 -9.008126 -4.384427   5.054848    voi  \n",
       "4 -2.876247  -4.629001 -7.439723 -9.067987 -6.983652   1.462925    voi  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"voi\", \"vio\", \"tru\", \"sax\", \"pia\", \"org\", \"gel\", \"gac\", \"flu\", \"cla\", \"cel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = le.transform(raw_data_all['label'])\n",
    "x_all = raw_data_all.drop(['label'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109.61838151 285.72876509 141.95353899 146.82711631  97.29848546\n",
      " 100.66832546  77.17568385  69.72930732  67.60932858  75.83187842\n",
      "  79.12927627  90.73181075  78.00221646  72.01479075  66.49828968\n",
      "  79.34808801  81.57805319  81.65627243  68.54574713  88.77420663\n",
      "  70.18624399  78.48115414  60.51033814  64.71805553  64.18162727\n",
      "  65.62119707  63.73484468  60.48609441  56.56611649  65.20246844\n",
      "  76.69662452  73.99370024  62.9391947   67.56181405  52.24818745\n",
      "  52.85312824  65.35498964  65.20700908  67.7478285   61.94813725]\n",
      "[[0.76329205 0.52181254 0.43886226 ... 0.37902533 0.41355379 0.55848558]\n",
      " [0.77103943 0.51268647 0.42804283 ... 0.37900911 0.46249013 0.56360389]\n",
      " [0.78837632 0.49809358 0.39140958 ... 0.37280283 0.46556662 0.55049863]\n",
      " ...\n",
      " [0.68577026 0.52850308 0.48033929 ... 0.48138761 0.40708729 0.46328231]\n",
      " [0.67922243 0.55801826 0.46962184 ... 0.47235934 0.41916292 0.42660999]\n",
      " [0.65649024 0.57141765 0.47877721 ... 0.46146527 0.47959007 0.44498139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_all)\n",
    "print(scaler.data_max_)\n",
    "x_all_scaled = scaler.transform(x_all)\n",
    "print(x_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(871650, 40)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Train_Test_Splitå¾—åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "x_train, x_test, y_train, y_test  = train_test_split(x_all_scaled, y_all, test_size = 0.1, random_state = 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.array(x_train).reshape(784485, 1, 40)\n",
    "train_label = np.array(y_train)\n",
    "test_set = np.array(x_test).reshape(87165, 1, 40)\n",
    "test_label = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784485, 1, 40)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784485"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87165, 1, 40)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.78262429, 0.49057644, 0.61388665, ..., 0.43361695,\n",
       "         0.48280001, 0.51645733]],\n",
       "\n",
       "       [[0.85775929, 0.33186216, 0.51272962, ..., 0.55392075,\n",
       "         0.54664866, 0.50176695]],\n",
       "\n",
       "       [[0.80194414, 0.50511566, 0.48071963, ..., 0.40385252,\n",
       "         0.41255284, 0.49535454]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.51788485, 0.78104154, 0.51238143, ..., 0.37899639,\n",
       "         0.5174551 , 0.55353914]],\n",
       "\n",
       "       [[0.74068903, 0.5930379 , 0.4377077 , ..., 0.48298273,\n",
       "         0.18092639, 0.52902532]],\n",
       "\n",
       "       [[0.71326946, 0.60884322, 0.55558095, ..., 0.34539109,\n",
       "         0.49684364, 0.50179653]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(train_label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_onehot = enc.transform(train_label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_onehot.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_onehot = enc.transform(test_label.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(1, 40)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(64, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(11, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "784485/784485 [==============================] - 41s 52us/step - loss: 1.7839 - acc: 0.3870 1s - loss:\n",
      "Epoch 2/10\n",
      "784485/784485 [==============================] - 41s 52us/step - loss: 1.5991 - acc: 0.4549\n",
      "Epoch 3/10\n",
      "784485/784485 [==============================] - 41s 53us/step - loss: 1.5211 - acc: 0.4827A:\n",
      "Epoch 4/10\n",
      "784485/784485 [==============================] - 42s 53us/step - loss: 1.4798 - acc: 0.4975\n",
      "Epoch 5/10\n",
      "784485/784485 [==============================] - 43s 55us/step - loss: 1.4455 - acc: 0.5097 0s - loss: 1.4455 - \n",
      "Epoch 6/10\n",
      "784485/784485 [==============================] - 44s 56us/step - loss: 1.4150 - acc: 0.5193\n",
      "Epoch 7/10\n",
      "784485/784485 [==============================] - 47s 60us/step - loss: 1.3891 - acc: 0.5291 7s - loss - ETA: 5s - loss: 1.3898 -  - ETA: 4s - loss: 1.38 -  - ETA: 0s - loss: 1.3892 - acc: 0.5\n",
      "Epoch 8/10\n",
      "784485/784485 [==============================] - 47s 59us/step - loss: 1.3645 - acc: 0.5378\n",
      "Epoch 9/10\n",
      "784485/784485 [==============================] - 46s 58us/step - loss: 1.3428 - acc: 0.5457 7s - loss: 1.3 - ETA: 4s - loss: 1.3435 - acc\n",
      "Epoch 10/10\n",
      "784485/784485 [==============================] - 50s 64us/step - loss: 1.3226 - acc: 0.5528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4842fe48>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_full = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.13714035e-02, 7.25069176e-03, 5.63760567e-03, 1.90432034e-02,\n",
       "        5.60894728e-01, 5.72656244e-02, 5.53173653e-04, 1.25235632e-01,\n",
       "        6.09396435e-02, 2.92775836e-02, 1.02530666e-01],\n",
       "       [1.67146474e-01, 5.30439371e-04, 2.99736828e-04, 6.44245744e-03,\n",
       "        1.18650362e-01, 2.58437485e-05, 1.89952576e-03, 7.73263024e-03,\n",
       "        6.89056277e-01, 6.90427702e-03, 1.31202897e-03],\n",
       "       [1.97654910e-04, 6.35374710e-02, 2.22683419e-02, 8.94161910e-02,\n",
       "        1.13926234e-03, 1.29209633e-03, 2.19856836e-02, 7.90531874e-01,\n",
       "        6.39198441e-03, 3.03420215e-03, 2.05301723e-04]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_full[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, (3), input_shape=(1,40), activation='relu', padding=\"same\"))\n",
    "model.add(Conv1D(32, (3), activation='relu', padding=\"same\"))\n",
    "model.add(Conv1D(32, (3), activation='relu', padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "784485/784485 [==============================] - 17s 22us/step - loss: 2.2211 - acc: 0.1858\n",
      "Epoch 2/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 2.1277 - acc: 0.2232\n",
      "Epoch 3/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 2.0454 - acc: 0.2737\n",
      "Epoch 4/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.9403 - acc: 0.3267\n",
      "Epoch 5/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.8881 - acc: 0.3438\n",
      "Epoch 6/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.8491 - acc: 0.3586\n",
      "Epoch 7/100\n",
      "784485/784485 [==============================] - 21s 26us/step - loss: 1.8185 - acc: 0.3723\n",
      "Epoch 8/100\n",
      "784485/784485 [==============================] - 17s 22us/step - loss: 1.7897 - acc: 0.3849 1\n",
      "Epoch 9/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.7632 - acc: 0.3955\n",
      "Epoch 10/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.7362 - acc: 0.4058\n",
      "Epoch 11/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.7138 - acc: 0.4149\n",
      "Epoch 12/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.6953 - acc: 0.4211\n",
      "Epoch 13/100\n",
      "784485/784485 [==============================] - 15s 20us/step - loss: 1.6795 - acc: 0.4269\n",
      "Epoch 14/100\n",
      "784485/784485 [==============================] - 15s 20us/step - loss: 1.6657 - acc: 0.4316\n",
      "Epoch 15/100\n",
      "784485/784485 [==============================] - 17s 21us/step - loss: 1.6545 - acc: 0.4353\n",
      "Epoch 16/100\n",
      "784485/784485 [==============================] - 15s 20us/step - loss: 1.6429 - acc: 0.4396 3s \n",
      "Epoch 17/100\n",
      "784485/784485 [==============================] - 14s 18us/step - loss: 1.6332 - acc: 0.4429\n",
      "Epoch 18/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.6237 - acc: 0.4457\n",
      "Epoch 19/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.6143 - acc: 0.4491\n",
      "Epoch 20/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.6062 - acc: 0.4516\n",
      "Epoch 21/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.5987 - acc: 0.4545 1s - loss: 1. - ETA: 0s - loss: 1.5987 - acc\n",
      "Epoch 22/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.5919 - acc: 0.4565\n",
      "Epoch 23/100\n",
      "784485/784485 [==============================] - 14s 18us/step - loss: 1.5858 - acc: 0.4580\n",
      "Epoch 24/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5807 - acc: 0.4598 - ETA: 1s - loss: 1.5812 - - ETA: 1s - loss\n",
      "Epoch 25/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.5744 - acc: 0.4617\n",
      "Epoch 26/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5692 - acc: 0.4639\n",
      "Epoch 27/100\n",
      "784485/784485 [==============================] - 16s 21us/step - loss: 1.5636 - acc: 0.4656 5s  - ETA: 1s - - ETA: 0s - loss: 1.5635 - acc: 0.\n",
      "Epoch 28/100\n",
      "784485/784485 [==============================] - 15s 20us/step - loss: 1.5588 - acc: 0.4679\n",
      "Epoch 29/100\n",
      "784485/784485 [==============================] - 15s 20us/step - loss: 1.5548 - acc: 0.4689 9s -  - ETA: 8s - loss: 1.5582 -  - ETA: 7s - loss: 1.5575 - acc: 0.4 - ETA: 7s -  -  - ETA: 2s - - ETA: 0s - loss: 1.5547 \n",
      "Epoch 30/100\n",
      "784485/784485 [==============================] - 15s 19us/step - loss: 1.5510 - acc: 0.4701\n",
      "Epoch 31/100\n",
      "784485/784485 [==============================] - 17s 22us/step - loss: 1.5472 - acc: 0.4712 3s - lo\n",
      "Epoch 32/100\n",
      "784485/784485 [==============================] - 17s 21us/step - loss: 1.5430 - acc: 0.4729\n",
      "Epoch 33/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5403 - acc: 0.4738\n",
      "Epoch 34/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5370 - acc: 0.4756\n",
      "Epoch 35/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5350 - acc: 0.4757\n",
      "Epoch 36/100\n",
      "784485/784485 [==============================] - 16s 21us/step - loss: 1.5319 - acc: 0.4760\n",
      "Epoch 37/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5292 - acc: 0.4778\n",
      "Epoch 38/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5271 - acc: 0.4784 0s - loss: 1.5269 - ac - ETA: 0s - loss: 1.5272 - acc: \n",
      "Epoch 39/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5236 - acc: 0.4792\n",
      "Epoch 40/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5219 - acc: 0.4796\n",
      "Epoch 41/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5200 - acc: 0.4807 0s - loss: 1.5198 - acc: \n",
      "Epoch 42/100\n",
      "784485/784485 [==============================] - 17s 21us/step - loss: 1.5175 - acc: 0.4811\n",
      "Epoch 43/100\n",
      "784485/784485 [==============================] - 16s 20us/step - loss: 1.5157 - acc: 0.4817\n",
      "Epoch 44/100\n",
      "784485/784485 [==============================] - 22s 28us/step - loss: 1.5138 - acc: 0.4829\n",
      "Epoch 45/100\n",
      " 44032/784485 [>.............................] - ETA: 19s - loss: 1.5130 - acc: 0.4817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-bada45d97fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           verbose=1)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     93\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   4117\u001b[0m     \"\"\"\n\u001b[1;32m   4118\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 4119\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   4120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   4031\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4033\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4171\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m         \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "model.fit(train_set, train_label_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, (3), input_shape=(1,40), activation='relu', padding=\"same\"))\n",
    "model.add(Conv1D(32, (3), activation='relu', padding=\"same\"))\n",
    "model.add(Conv1D(32, (3), activation='relu', padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='softmax'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "784485/784485 [==============================] - 27s 35us/step - loss: 2.3801 - acc: 0.1155\n",
      "Epoch 2/10\n",
      "784485/784485 [==============================] - 22s 28us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 3/10\n",
      "784485/784485 [==============================] - 24s 30us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 4/10\n",
      "784485/784485 [==============================] - 26s 33us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 5/10\n",
      "784485/784485 [==============================] - 23s 29us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 6/10\n",
      "784485/784485 [==============================] - 22s 28us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 7/10\n",
      "784485/784485 [==============================] - 22s 28us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 8/10\n",
      "784485/784485 [==============================] - 22s 28us/step - loss: 2.3781 - acc: 0.1160\n",
      "Epoch 9/10\n",
      "784485/784485 [==============================] - 24s 31us/step - loss: 2.3781 - acc: 0.1160 0s - loss: 2.3781 - acc: 0.11\n",
      "Epoch 10/10\n",
      "784485/784485 [==============================] - 25s 32us/step - loss: 2.3781 - acc: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4632a9e8>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(train_set, train_label_onehot,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
